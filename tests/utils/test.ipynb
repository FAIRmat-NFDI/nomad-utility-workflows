{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `nomad_utility_workflows` to perform NOMAD API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "from nomad_utility_workflows.utils.users import (\n",
    "    get_user_by_id, who_am_i, search_users_by_name\n",
    ")\n",
    "from nomad_utility_workflows.utils.utils import get_authentication_token\n",
    "from nomad_utility_workflows.utils.entries import (\n",
    "    get_entry_by_id, get_entries_of_upload, query_entries, get_entries_of_my_uploads,\n",
    "    download_entry_by_id\n",
    ")\n",
    "from nomad_utility_workflows.utils.datasets import (\n",
    "    retrieve_datasets, create_dataset, delete_dataset, get_dataset_by_id\n",
    ")\n",
    "from nomad_utility_workflows.utils.uploads import (\n",
    "    upload_files_to_nomad, get_upload_by_id, publish_upload, edit_upload_metadata,\n",
    "    get_all_my_uploads, delete_upload\n",
    ")\n",
    "\n",
    "from decouple import config as environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOMAD URLs\n",
    "\n",
    "The NOMAD URL specifies the base address of the API for the NOMAD deployment of interest. Typically, this URL is structured as `https://<deployment_base_path>/api/v1`.\n",
    "\n",
    "By default, `nomad_utility_workflows` uses the Test deployment of NOMAD to make API calls. This is simply a safety mechanism so that users do not accidentally publish something during testing. \n",
    "\n",
    "All API functions allow the user to specify the URL with the optional keyword argument `url`. If you want to use the central NOMAD URLs, you can simply set `url` equal to `prod`, `staging`, or `test`, which correspond to the following deployments (see full URLs below):\n",
    "\n",
    "- prod: the official NOMAD deployment. \n",
    "    - Updated most infrequently (as advertised in #software-updates on the NOMAD Discord Server)\n",
    "- staging: the beta version of NOMAD. \n",
    "    - Updated more frequently than prod, integrating new features. \n",
    "- test: a test NOMAD deployment. \n",
    "    - The data is occassionally wiped, such that test publishing can be made.\n",
    "\n",
    "Note that the `prod` and `staging` deployments share a common database, and that publishing on either will result in publically available data.\n",
    "\n",
    "Alternatively to these short names, the user can use the `url` input to specify the full API address to some alternative NOMAD deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://nomad-lab.eu/prod/v1/api/v1 https://nomad-lab.eu/prod/v1/staging/api/v1 https://nomad-lab.eu/prod/v1/test/api/v1\n"
     ]
    }
   ],
   "source": [
    "from nomad_utility_workflows.utils.utils import NOMAD_TEST_URL, NOMAD_STAGING_URL, NOMAD_PROD_URL\n",
    "print(NOMAD_PROD_URL, NOMAD_STAGING_URL, NOMAD_TEST_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "Some API calls, e.g., making uploads or accessing your own non-published uploads, require an authentication token. To generate this token, `nomad_utility_workflows` expects that your NOMAD credentials are stored in a `.env` file in the plugin root directory in the format:\n",
    "\n",
    "```bash\n",
    "NOMAD_USERNAME=\"<your_nomad_username>\"\n",
    "NOMAD_PASSWORD=\"<your_nomad_password>\"\n",
    "```\n",
    "\n",
    "You can access these explicitly with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JFRudzinski'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOMAD_USERNAME = environ(\"NOMAD_USERNAME\")\n",
    "NOMAD_PASSWORD = environ(\"NOMAD_PASSWORD\")\n",
    "NOMAD_USERNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `get_authentication_token()` with your credentials to explicitly obtain and store a token (`nomad_utility_workflows()` will automatically obtain a token for API calls that require authentication):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJmb1hmZnM5QlFQWHduLU54Yk5PYlExOFhnZnlKU1FNRkl6ZFVnWjhrZzdVIn0.eyJleHAiOjE3MjkwNzM4NzcsImlhdCI6MTcyODk4NzQ3NywianRpIjoiOGQ0ODgwYTAtY2VlOS00NDMyLTliOGUtNTBjNGI5YzgzOWI2IiwiaXNzIjoiaHR0cHM6Ly9ub21hZC1sYWIuZXUvZmFpcmRpL2tleWNsb2FrL2F1dGgvcmVhbG1zL2ZhaXJkaV9ub21hZF9wcm9kIiwic3ViIjoiOGYwNTJlMWYtMTkwNi00MWZkLWIyZWItNjkwYzAzNDA3Nzg4IiwidHlwIjoiQmVhcmVyIiwiYXpwIjoibm9tYWRfcHVibGljIiwic2Vzc2lvbl9zdGF0ZSI6Ijc2NzM0NTYxLTVmMzgtNGUyMS1hYzZiLTU4OTlmZDVjZmI4ZiIsInNjb3BlIjoib3BlbmlkIHByb2ZpbGUgZW1haWwiLCJzaWQiOiI3NjczNDU2MS01ZjM4LTRlMjEtYWM2Yi01ODk5ZmQ1Y2ZiOGYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwibmFtZSI6Ikpvc2VwaCBSdWR6aW5za2kiLCJwcmVmZXJyZWRfdXNlcm5hbWUiOiJqZnJ1ZHppbnNraSIsImdpdmVuX25hbWUiOiJKb3NlcGgiLCJmYW1pbHlfbmFtZSI6IlJ1ZHppbnNraSIsImVtYWlsIjoicnVkemluc2tpQG1waXAtbWFpbnoubXBnLmRlIn0.Z4FKIpUgYYPVmopYc6iW5U7ENTxgRKQq29pDbllsKGsbsj5cqCTvYbj3RB2tsN99bjV_2SJ3qkH9GSgyamZ558bcPDJvS-KBGYBb-CcJ0QrKyJoa0jJwcVc4ibHuqY0PNVs5c5eubtDb1xGoRWdFxjxrcGXxHrYSn1dgSKPCKA3B-GdkcSr0R60f-MOiLN9ONKMc4JxrMexJKdtxZCaDJVFzePACH5qkzC2l-ZiFYp86w4vOt3hQqZPTGl1SKo6RTSme2p4QQxa0IG31h-HJ1lbTJsPFjh1Yh9KROz8zuGZJLLZCHdbp2k_ktBbFehdPL2dbkST3-F1LGkuyx_1Tiw'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = get_authentication_token(username=NOMAD_USERNAME, password=NOMAD_PASSWORD, url='test')\n",
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOMAD User Metadata\n",
    "\n",
    "`nomad_utility_workflows` uses the `NomadUser()` class to store the following user metadata:\n",
    "\n",
    "```python\n",
    "class NomadUser:\n",
    "    user_id: str\n",
    "    name: str\n",
    "    first_name: str \n",
    "    last_name: str \n",
    "    username: str \n",
    "    affiliation: str \n",
    "    affiliation_address: str \n",
    "    email: str\n",
    "    is_oasis_admin: bool \n",
    "    is_admin: bool\n",
    "    repo_user_id: str \n",
    "    created: dt.datetime\n",
    "```\n",
    "\n",
    "\n",
    "You can retrieve your own personal info with the `who_am_i()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NomadUser(name='Joseph Rudzinski')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomad_user_me = who_am_i(url='test')\n",
    "nomad_user_me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, you can query NOMAD for other users with `search_users_by_name()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NomadUser(name='Joseph Rudzinski'), NomadUser(name='Joseph Rudzinski')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomad_users = search_users_by_name('Rudzinski', url='test')\n",
    "nomad_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of multiple matches or for robustly identifying particular users, e.g., coauthors, in the future, it may be useful to store their `user_id`&mdash;a persistent identifier for each user account. Then, in the future you can use `get_user_by_id()` to grab the user info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NomadUser(name='Joseph Rudzinski')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomad_user = get_user_by_id(nomad_users[0].user_id, url='test')\n",
    "nomad_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Data\n",
    "\n",
    "`nomad_utility_workflows` uses the `NomadUpload()` class to store the following upload metadata:\n",
    "\n",
    "```python\n",
    "class NomadUpload:\n",
    "    upload_id: str\n",
    "    upload_create_time: dt.datetime\n",
    "    main_author: NomadUser\n",
    "    process_running: bool\n",
    "    current_process: str\n",
    "    process_status: str\n",
    "    last_status_message: str\n",
    "    errors: list[Any]\n",
    "    warnings: list[Any]\n",
    "    coauthors: list[str]\n",
    "    coauthor_groups: list[Any]\n",
    "    reviewers: list[NomadUser]\n",
    "    reviewer_groups: list[Any]\n",
    "    writers: list[NomadUser]\n",
    "    writer_groups: list[Any]\n",
    "    viewers: list[NomadUser]\n",
    "    viewer_groups: list[Any]\n",
    "    published: bool\n",
    "    published_to: list[Any]\n",
    "    with_embargo: bool\n",
    "    embargo_length: float\n",
    "    license: str\n",
    "    entries: int\n",
    "    n_entries: Optional[int] \n",
    "    upload_files_server_path: Optional[str] \n",
    "    publish_time: Optional[dt.datetime] \n",
    "    references: Optional[list[str]] \n",
    "    datasets: Optional[list[str]] \n",
    "    external_db: Optional[str] \n",
    "    upload_name: Optional[str]\n",
    "    comment: Optional[str] \n",
    "    url: Optional[str]\n",
    "    complete_time: Optional[dt.datetime]\n",
    "```\n",
    "\n",
    "You can make an upload using the `upload_files_to_nomad()` function with input `filename=<path_to_a_zip_file_with_your_upload_data>`, as follows:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_upload_fnm = './test.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GJdVAOCxRVe-Cwo3qMz9Kg'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_id = upload_files_to_nomad(filename=test_upload_fnm, url='test')\n",
    "upload_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the upload status\n",
    "\n",
    "The returned `upload_id` can then be used to directly access the upload, e.g., to check the upload status, using `get_upload_by_id()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NomadUpload(upload_id='GJdVAOCxRVe-Cwo3qMz9Kg',\n",
      "            upload_create_time=datetime.datetime(2024, 10, 15, 10, 48, 44, 337000),\n",
      "            main_author=NomadUser(name='Joseph Rudzinski'),\n",
      "            process_running=False,\n",
      "            current_process='edit_upload_metadata',\n",
      "            process_status='SUCCESS',\n",
      "            last_status_message='Process edit_upload_metadata completed '\n",
      "                                'successfully',\n",
      "            errors=[],\n",
      "            warnings=[],\n",
      "            coauthors=[],\n",
      "            coauthor_groups=[],\n",
      "            reviewers=[],\n",
      "            reviewer_groups=[],\n",
      "            writers=[NomadUser(name='Joseph Rudzinski')],\n",
      "            writer_groups=[],\n",
      "            viewers=[NomadUser(name='Joseph Rudzinski')],\n",
      "            viewer_groups=[],\n",
      "            published=True,\n",
      "            published_to=[],\n",
      "            with_embargo=False,\n",
      "            embargo_length=0.0,\n",
      "            license='CC BY 4.0',\n",
      "            entries=1,\n",
      "            n_entries=None,\n",
      "            upload_files_server_path=None,\n",
      "            publish_time=datetime.datetime(2024, 10, 15, 10, 49, 24, 4000),\n",
      "            references=None,\n",
      "            datasets=None,\n",
      "            external_db=None,\n",
      "            upload_name='Test Upload',\n",
      "            comment=None,\n",
      "            url='https://nomad-lab.eu/prod/v1/test/api/v1',\n",
      "            complete_time=datetime.datetime(2024, 10, 15, 10, 49, 30, 962000))\n"
     ]
    }
   ],
   "source": [
    "nomad_upload = get_upload_by_id(upload_id, url='test')\n",
    "\n",
    "pprint(nomad_upload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common usage of this function is to ensure that an upload has been processed successfully before making a subsequent action on it, e.g., editing the metadata or publishing. For this purpose, one could require the `process_running==False` or `process_status='SUCCESS'`, e.g.:\n",
    "\n",
    "```python\n",
    "    import time\n",
    "\n",
    "    max_wait_time = 20 * 60  # 20 minutes in seconds\n",
    "    interval = 2 * 60  # 2 minutes in seconds\n",
    "    elapsed_time = 0\n",
    "\n",
    "    while elapsed_time < max_wait_time:\n",
    "        nomad_upload = get_upload_by_id(upload_id, url='test')\n",
    "        \n",
    "        # Check if the upload is complete\n",
    "        if nomad_upload.process_status == 'SUCCESS':\n",
    "            break\n",
    "        \n",
    "        # Wait for 2 minutes before the next call\n",
    "        time.sleep(interval)\n",
    "        elapsed_time += interval\n",
    "    else:\n",
    "        raise TimeoutError(\"Maximum wait time of 20 minutes exceeded. Upload is not complete.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing the upload metadata\n",
    "\n",
    "After your upload is processed successfully, you can add coauthors, references, and other comments, as well as link to a dataset and provide a name for the upload. Note that the coauthor is specified by an email address that should correspond to the email linked to the person's NOMAD account, which can be access from `NomadUser.email`. The metadata should be stored as a dictionary as follows:\n",
    "\n",
    "```python\n",
    "metadata = {\n",
    "    \"metadata\": {\n",
    "    \"upload_name\": '<new_upload_name>',\n",
    "    \"references\": [\"https://doi.org/xx.xxxx/xxxxxx\"],\n",
    "    \"datasets\": '<dataset_id>',\n",
    "    \"embargo_length\": 0,\n",
    "    \"coauthors\": [\"coauthor@affiliation.de\"],\n",
    "    \"comment\": 'This is a test upload...'\n",
    "    },\n",
    "}\n",
    "```\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upload_id': 'GJdVAOCxRVe-Cwo3qMz9Kg',\n",
       " 'data': {'process_running': True,\n",
       "  'current_process': 'edit_upload_metadata',\n",
       "  'process_status': 'PENDING',\n",
       "  'last_status_message': 'Pending: edit_upload_metadata',\n",
       "  'errors': [],\n",
       "  'warnings': [],\n",
       "  'complete_time': '2024-10-15T10:48:45.852000',\n",
       "  'upload_id': 'GJdVAOCxRVe-Cwo3qMz9Kg',\n",
       "  'upload_create_time': '2024-10-15T10:48:44.337000',\n",
       "  'main_author': '8f052e1f-1906-41fd-b2eb-690c03407788',\n",
       "  'coauthors': [],\n",
       "  'coauthor_groups': [],\n",
       "  'reviewers': [],\n",
       "  'reviewer_groups': [],\n",
       "  'writers': ['8f052e1f-1906-41fd-b2eb-690c03407788'],\n",
       "  'writer_groups': [],\n",
       "  'viewers': ['8f052e1f-1906-41fd-b2eb-690c03407788'],\n",
       "  'viewer_groups': [],\n",
       "  'published': False,\n",
       "  'published_to': [],\n",
       "  'with_embargo': False,\n",
       "  'embargo_length': 0,\n",
       "  'license': 'CC BY 4.0',\n",
       "  'entries': 1,\n",
       "  'upload_files_server_path': '/nomad/test/fs/staging/G/GJdVAOCxRVe-Cwo3qMz9Kg'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_new = {'upload_name': \"Test Upload\", 'comment': \"This is a test upload...\"}\n",
    "edit_upload_metadata(upload_id, url='test', **metadata_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, let's again check that this additional process is complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "nomad_upload = get_upload_by_id(upload_id, url='test')\n",
    "\n",
    "pprint(nomad_upload.process_status=='SUCCESS')\n",
    "pprint(nomad_upload.process_running==False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing individual entries of an upload\n",
    "\n",
    "During the upload process, NOMAD automatically identfies representative files that indicate the presence of data that can be parsed with the plugins included within a given deployment. This means that each upload can contain multiple *entries*&mdash;the fundamental unit storage within the NOMAD database.\n",
    "\n",
    "You can query the individual entries within a known upload with `get_entries_of_upload()`, which then returns the metadata within the `NomadEntry()` class of `nomad-utility-worklfows`:\n",
    "\n",
    "```python\n",
    "class NomadEntry:\n",
    "    entry_id: str\n",
    "    upload_id: str\n",
    "    references: list[str]\n",
    "    origin: str\n",
    "    quantities: list[str] \n",
    "    datasets: list[NomadDataset] \n",
    "    n_quantities: int\n",
    "    nomad_version: str\n",
    "    upload_create_time: dt.datetime\n",
    "    nomad_commit: str\n",
    "    section_defs: list[NomadSectionDefinition] \n",
    "    processing_errors: list[Any]\n",
    "    results: dict\n",
    "    entry_name: str\n",
    "    last_processing_time: dt.datetime\n",
    "    parser_name: str\n",
    "    calc_id: str\n",
    "    published: bool\n",
    "    writers: list[NomadUser]\n",
    "    sections: list[str] \n",
    "    processed: bool\n",
    "    mainfile: str\n",
    "    main_author: NomadUser\n",
    "    viewers: list[NomadUser] \n",
    "    entry_create_time: dt.datetime\n",
    "    with_embargo: bool\n",
    "    files: list[str] \n",
    "    entry_type: str\n",
    "    authors: list[NomadUser] \n",
    "    license: str\n",
    "    domain: str\n",
    "    optimade: dict\n",
    "    comment: str\n",
    "    upload_name: str\n",
    "    viewer_groups: list[Any]\n",
    "    writer_groups: list[Any]\n",
    "    text_search_contents: list[str]\n",
    "    publish_time: Optional[dt.datetime] \n",
    "    entry_references: list[dict]\n",
    "    url: str\n",
    "```\n",
    "\n",
    "Let's try this out with our test upload. In this case, the upload is *not* published and located in the *private* `Your Uploads` sub-database of your NOMAD account. To access the uploads there, we need to set `with_authentication=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Entries within upload_id=GJdVAOCxRVe-Cwo3qMz9Kg:'\n",
      "'entry_id=MVBIMEZOuIzH7-QFU2TtMIM6LLPp'\n"
     ]
    }
   ],
   "source": [
    "entries = get_entries_of_upload(upload_id, url='test', with_authentication=True)\n",
    "pprint(f'Entries within upload_id={upload_id}:')\n",
    "for entry in entries:\n",
    "    pprint(f'entry_id={entry.entry_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query an entry directly using the `entry_id`, use `get_entry_by_id()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NomadEntry(entry_id='MVBIMEZOuIzH7-QFU2TtMIM6LLPp', upload_id='GJdVAOCxRVe-Cwo3qMz9Kg', references=[], origin='Joseph Rudzinski', n_quantities=0, nomad_version='1.3.7.dev55+ge83de27b3', upload_create_time=datetime.datetime(2024, 10, 15, 10, 48, 44, 337000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), nomad_commit='', processing_errors=[], entry_name='test.archive.json', last_processing_time=datetime.datetime(2024, 10, 15, 10, 48, 45, 206000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), parser_name='parsers/archive', calc_id='MVBIMEZOuIzH7-QFU2TtMIM6LLPp', published=False, writers=[NomadUser(name='Joseph Rudzinski')], processed=True, mainfile='test.archive.json', main_author=NomadUser(name='Joseph Rudzinski'), entry_create_time=datetime.datetime(2024, 10, 15, 10, 48, 44, 741000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), with_embargo=False, entry_type=None, license='CC BY 4.0', domain=None, comment='This is a test upload...', upload_name='Test Upload', text_search_contents=[], publish_time=None, entry_references=None, url='https://nomad-lab.eu/prod/v1/test/api/v1')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry = get_entry_by_id(entries[0].entry_id, url='test', with_authentication=True)\n",
    "entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the full (meta)data stored in an entry using `download_entry_by_id()`. This will return the entire archive as a dictionary. If you supply a `zip_file_name` (including the desired local path), the raw data of the entry will also be downloaded and saved to a zip file. Otherwise, only the archive will be downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'entry' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m download_entry_by_id(\u001b[43mentry\u001b[49m\u001b[38;5;241m.\u001b[39mentry_id, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprod\u001b[39m\u001b[38;5;124m'\u001b[39m, zip_file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./raw_entry_data.zip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m test\n",
      "\u001b[0;31mNameError\u001b[0m: name 'entry' is not defined"
     ]
    }
   ],
   "source": [
    "test = download_entry_by_id(entry.entry_id, url='test', zip_file_name='./raw_entry_data.zip')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publishing Uploads\n",
    "\n",
    "Once the processing of your upload is successful and you have added/adjusted the appropriate metadata, you can publish your upload with `publish_upload()`, making it publicly available on the corresponding NOMAD deployment. \n",
    "\n",
    "Note that once the upload is published you will no longer be able to make changes to the raw files that you uploaded. However, the upload metadata (accessed and edited in the above example) can be changed after publishing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upload_id': 'GJdVAOCxRVe-Cwo3qMz9Kg',\n",
       " 'data': {'process_running': True,\n",
       "  'current_process': 'publish_upload',\n",
       "  'process_status': 'PENDING',\n",
       "  'last_status_message': 'Pending: publish_upload',\n",
       "  'errors': [],\n",
       "  'warnings': [],\n",
       "  'complete_time': '2024-10-15T10:48:48.854000',\n",
       "  'upload_id': 'GJdVAOCxRVe-Cwo3qMz9Kg',\n",
       "  'upload_name': 'Test Upload',\n",
       "  'upload_create_time': '2024-10-15T10:48:44.337000',\n",
       "  'main_author': '8f052e1f-1906-41fd-b2eb-690c03407788',\n",
       "  'coauthors': [],\n",
       "  'coauthor_groups': [],\n",
       "  'reviewers': [],\n",
       "  'reviewer_groups': [],\n",
       "  'writers': ['8f052e1f-1906-41fd-b2eb-690c03407788'],\n",
       "  'writer_groups': [],\n",
       "  'viewers': ['8f052e1f-1906-41fd-b2eb-690c03407788'],\n",
       "  'viewer_groups': [],\n",
       "  'published': False,\n",
       "  'published_to': [],\n",
       "  'with_embargo': False,\n",
       "  'embargo_length': 0,\n",
       "  'license': 'CC BY 4.0',\n",
       "  'entries': 1,\n",
       "  'upload_files_server_path': '/nomad/test/fs/staging/G/GJdVAOCxRVe-Cwo3qMz9Kg'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "published_upload = publish_upload(nomad_upload.upload_id, url='test')\n",
    "published_upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding and Creating Datasets\n",
    "\n",
    "Although uploads can group multiple entries together, they are limited by the maximum upload size and act more as a practical tool for optimizing the transfer of data to the NOMAD repository. For scientifically relevant connections between entries, NOMAD uses *Datasets* and *Workflows*. \n",
    "\n",
    "You can easily create a dataset with `create_dataset()`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nc9xYRXPTi6mCeptdsYvzQ'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_id = create_dataset(\"test dataset\", url='test')\n",
    "dataset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned `dataset_id` can then be used to add individual entries (or all entries within an upload) to the dataset by including it in the upload/entry metadata, using the method described above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upload_id': 'GJdVAOCxRVe-Cwo3qMz9Kg',\n",
       " 'data': {'process_running': True,\n",
       "  'current_process': 'edit_upload_metadata',\n",
       "  'process_status': 'PENDING',\n",
       "  'last_status_message': 'Pending: edit_upload_metadata',\n",
       "  'errors': [],\n",
       "  'warnings': [],\n",
       "  'complete_time': '2024-10-15T10:49:24.014000',\n",
       "  'upload_id': 'GJdVAOCxRVe-Cwo3qMz9Kg',\n",
       "  'upload_name': 'Test Upload',\n",
       "  'upload_create_time': '2024-10-15T10:48:44.337000',\n",
       "  'main_author': '8f052e1f-1906-41fd-b2eb-690c03407788',\n",
       "  'coauthors': [],\n",
       "  'coauthor_groups': [],\n",
       "  'reviewers': [],\n",
       "  'reviewer_groups': [],\n",
       "  'writers': ['8f052e1f-1906-41fd-b2eb-690c03407788'],\n",
       "  'writer_groups': [],\n",
       "  'viewers': ['8f052e1f-1906-41fd-b2eb-690c03407788'],\n",
       "  'viewer_groups': [],\n",
       "  'published': True,\n",
       "  'published_to': [],\n",
       "  'publish_time': '2024-10-15T10:49:24.004000',\n",
       "  'with_embargo': False,\n",
       "  'embargo_length': 0,\n",
       "  'license': 'CC BY 4.0',\n",
       "  'entries': 1}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_new = {'dataset_id': dataset_id}\n",
    "edit_upload_metadata(upload_id, url='test', **metadata_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "nomad_upload = get_upload_by_id(upload_id, url='test')\n",
    "\n",
    "pprint(nomad_upload.process_status=='SUCCESS')\n",
    "pprint(nomad_upload.process_running==False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "You can also retrieve the dataset metadata using the `dataset_id` with `get_dataset_by_id()`. The returned `NomadDataset()` class contains the following attributes:\n",
    "\n",
    "```python\n",
    "class NomadDataset:\n",
    "    dataset_id: str\n",
    "    dataset_create_time: dt.datetime\n",
    "    dataset_name: str\n",
    "    dataset_type: str\n",
    "    dataset_modified_time: dt.datetime\n",
    "    user: NomadUser\n",
    "    doi: str\n",
    "    pid: int\n",
    "    m_annotations: dict\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NomadDataset(dataset_id='Nc9xYRXPTi6mCeptdsYvzQ', dataset_create_time=datetime.datetime(2024, 10, 15, 10, 32, 21, 3000), dataset_name='test dataset', dataset_type='owned', dataset_modified_time=datetime.datetime(2024, 10, 15, 10, 32, 21, 3000), user=NomadUser(name='Joseph Rudzinski'), doi=None, pid=None, m_annotations=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomad_dataset = get_dataset_by_id(dataset_id, url='test')\n",
    "nomad_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can search for datasets, e.g., by `user_id` or `dataset_name`, using `retrieve_datasets()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NomadDataset(dataset_id='Nc9xYRXPTi6mCeptdsYvzQ',\n",
      "              dataset_create_time=datetime.datetime(2024, 10, 15, 10, 32, 21, 3000),\n",
      "              dataset_name='test dataset',\n",
      "              dataset_type='owned',\n",
      "              dataset_modified_time=datetime.datetime(2024, 10, 15, 10, 32, 21, 3000),\n",
      "              user=NomadUser(name='Joseph Rudzinski'),\n",
      "              doi=None,\n",
      "              pid=None,\n",
      "              m_annotations=None)]\n"
     ]
    }
   ],
   "source": [
    "my_datasets = retrieve_datasets(user_id=nomad_user_me.user_id, url='test', max_datasets=20)\n",
    "pprint(my_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the list of entries contained within a dataset, use `query_entries()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'entry_id=MVBIMEZOuIzH7-QFU2TtMIM6LLPp, upload_id=GJdVAOCxRVe-Cwo3qMz9Kg'\n"
     ]
    }
   ],
   "source": [
    "dataset_entries = query_entries(dataset_id=dataset_id, url='test')\n",
    "for entry in dataset_entries:\n",
    "    pprint(f'entry_id={entry.entry_id}, upload_id={entry.upload_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no \"publishing\" action for datasets. Instead, when the dataset is complete (i.e., you are ready to fix the contents of the dataset), you can *assign a DOI*. There is currently no API action for this within `nomad-utility-workflows`. You must go to the GUI of the relevant deployment, go to `PUBLISH > Datasets`, find the dataset, and then click the \"assign a DOI\" banner icon to the right of the dataset entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Uploads and Datasets\n",
    "\n",
    "You can delete uploads and datasets using `delete_upload()` and `delete_dataset()` as demonstrated in the following examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Upload with upload_id=p4YWSItNSjiV-lt6ltYBFA was deleted successfully.'\n"
     ]
    }
   ],
   "source": [
    "# Make a dummy upload\n",
    "upload_id = upload_files_to_nomad(filename=test_upload_fnm, url='test')\n",
    "\n",
    "\n",
    "max_wait_time = 30  # 30 seconds\n",
    "interval = 10  # 10 seconds\n",
    "elapsed_time = 0\n",
    "\n",
    "while elapsed_time < max_wait_time:\n",
    "    # Get the upload\n",
    "    nomad_upload = get_upload_by_id(upload_id, url='test')\n",
    "\n",
    "    # Check if the upload is complete\n",
    "    if nomad_upload.process_status == 'SUCCESS':\n",
    "        break\n",
    "\n",
    "    # Wait for 2 minutes before the next call\n",
    "    time.sleep(interval)\n",
    "    elapsed_time += interval\n",
    "else:\n",
    "    raise TimeoutError(\"Maximum wait time of 20 minutes exceeded. Upload is not complete.\")\n",
    "\n",
    "# Delete the upload\n",
    "delete_upload(upload_id, url='test')\n",
    "\n",
    "# Wait for 10 seconds to make sure deletion is complete\n",
    "time.sleep(10)\n",
    "\n",
    "# Check if the upload was deleted\n",
    "try:\n",
    "    get_upload_by_id(upload_id, url='test')\n",
    "except Exception:\n",
    "    pprint(f'Upload with upload_id={upload_id} was deleted successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Dataset with dataset_id=NSV6KhvkTR2kxWapvC3n0w was deleted successfully.'\n"
     ]
    }
   ],
   "source": [
    "# Make a dummy dataset\n",
    "dataset_id = create_dataset(\"dummy dataset\", url='test')\n",
    "\n",
    "# Wait for 5 seconds to make sure dataset is created\n",
    "time.sleep(5)\n",
    "\n",
    "# Ensure the dataset was created\n",
    "dummy_dataset = get_dataset_by_id(dataset_id, url='test')\n",
    "assert dummy_dataset.dataset_id == dataset_id\n",
    "\n",
    "# Delete the upload\n",
    "delete_dataset(dataset_id, url='test')\n",
    "\n",
    "# Wait for 5 seconds to make sure deletion is complete\n",
    "time.sleep(5)\n",
    "\n",
    "# Check if the dataset was deleted\n",
    "try:\n",
    "    get_dataset_by_id(dataset_id, url='test')\n",
    "except Exception:\n",
    "    pprint(f'Dataset with dataset_id={dataset_id} was deleted successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Wrappers\n",
    "\n",
    "`nomad-utility-workflows` contains a few useful wrapper functions to help users query all of their uploads and corresponding entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NomadUpload(upload_id='bQa5SGDQQ8auQUBb5AaYHw', upload_create_time=datetime.datetime(2024, 10, 14, 10, 48, 40, 994000), main_author=NomadUser(name='Joseph Rudzinski'), process_running=False, current_process='publish_upload', process_status='SUCCESS', last_status_message='Process publish_upload completed successfully', errors=[], warnings=[], coauthors=[], coauthor_groups=[], reviewers=[], reviewer_groups=[], writers=[NomadUser(name='Joseph Rudzinski')], writer_groups=[], viewers=[NomadUser(name='Joseph Rudzinski')], viewer_groups=[], published=True, published_to=[], with_embargo=False, embargo_length=0.0, license='CC BY 4.0', entries=1, n_entries=None, upload_files_server_path=None, publish_time=datetime.datetime(2024, 10, 14, 10, 48, 55, 806000), references=None, datasets=None, external_db=None, upload_name='Test Upload', comment=None, url='https://nomad-lab.eu/prod/v1/test/api/v1', complete_time=datetime.datetime(2024, 10, 14, 10, 48, 55, 818000)),\n",
       " NomadUpload(upload_id='DN61X4r7SCyzm5q1kxcEcw', upload_create_time=datetime.datetime(2024, 10, 14, 10, 55, 12, 410000), main_author=NomadUser(name='Joseph Rudzinski'), process_running=False, current_process='publish_upload', process_status='SUCCESS', last_status_message='Process publish_upload completed successfully', errors=[], warnings=[], coauthors=[], coauthor_groups=[], reviewers=[], reviewer_groups=[], writers=[NomadUser(name='Joseph Rudzinski')], writer_groups=[], viewers=[NomadUser(name='Joseph Rudzinski')], viewer_groups=[], published=True, published_to=[], with_embargo=False, embargo_length=0.0, license='CC BY 4.0', entries=1, n_entries=None, upload_files_server_path=None, publish_time=datetime.datetime(2024, 10, 14, 10, 55, 23, 52000), references=None, datasets=None, external_db=None, upload_name='Test Upload', comment=None, url='https://nomad-lab.eu/prod/v1/test/api/v1', complete_time=datetime.datetime(2024, 10, 14, 10, 55, 23, 65000)),\n",
       " NomadUpload(upload_id='z4QvhZ7qSCmgIFv_qJqlyQ', upload_create_time=datetime.datetime(2024, 10, 14, 20, 20, 38, 757000), main_author=NomadUser(name='Joseph Rudzinski'), process_running=False, current_process='edit_upload_metadata', process_status='SUCCESS', last_status_message='Process edit_upload_metadata completed successfully', errors=[], warnings=[], coauthors=['7c85bdf1-8b53-40a8-81a4-04f26ff56f29'], coauthor_groups=[], reviewers=[], reviewer_groups=[], writers=[NomadUser(name='Joseph Rudzinski'), NomadUser(name='Joseph Rudzinski')], writer_groups=[], viewers=[NomadUser(name='Joseph Rudzinski'), NomadUser(name='Joseph Rudzinski')], viewer_groups=[], published=True, published_to=[], with_embargo=False, embargo_length=0.0, license='CC BY 4.0', entries=1, n_entries=None, upload_files_server_path=None, publish_time=datetime.datetime(2024, 10, 15, 6, 18, 27, 700000), references=None, datasets=None, external_db=None, upload_name='Test Upload', comment=None, url='https://nomad-lab.eu/prod/v1/test/api/v1', complete_time=datetime.datetime(2024, 10, 15, 6, 22, 33, 45000)),\n",
       " NomadUpload(upload_id='GJdVAOCxRVe-Cwo3qMz9Kg', upload_create_time=datetime.datetime(2024, 10, 15, 10, 48, 44, 337000), main_author=NomadUser(name='Joseph Rudzinski'), process_running=False, current_process='edit_upload_metadata', process_status='SUCCESS', last_status_message='Process edit_upload_metadata completed successfully', errors=[], warnings=[], coauthors=[], coauthor_groups=[], reviewers=[], reviewer_groups=[], writers=[NomadUser(name='Joseph Rudzinski')], writer_groups=[], viewers=[NomadUser(name='Joseph Rudzinski')], viewer_groups=[], published=True, published_to=[], with_embargo=False, embargo_length=0.0, license='CC BY 4.0', entries=1, n_entries=None, upload_files_server_path=None, publish_time=datetime.datetime(2024, 10, 15, 10, 49, 24, 4000), references=None, datasets=None, external_db=None, upload_name='Test Upload', comment=None, url='https://nomad-lab.eu/prod/v1/test/api/v1', complete_time=datetime.datetime(2024, 10, 15, 10, 49, 30, 962000))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_my_uploads(url='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NomadEntry(entry_id='ycdeXhPDG-nIgEQlqBfzIEKPWCvy', upload_id='bQa5SGDQQ8auQUBb5AaYHw', references=[], origin='Joseph Rudzinski', n_quantities=34, nomad_version='1.3.7.dev55+ge83de27b3', upload_create_time=datetime.datetime(2024, 10, 14, 10, 48, 40, 994000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), nomad_commit='', processing_errors=[], entry_name='test.archive.json', last_processing_time=datetime.datetime(2024, 10, 14, 10, 48, 42, 415000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), parser_name='parsers/archive', calc_id='ycdeXhPDG-nIgEQlqBfzIEKPWCvy', published=True, writers=[NomadUser(name='Joseph Rudzinski')], processed=True, mainfile='test.archive.json', main_author=NomadUser(name='Joseph Rudzinski'), entry_create_time=datetime.datetime(2024, 10, 14, 10, 48, 41, 672000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), with_embargo=False, entry_type=None, license='CC BY 4.0', domain=None, comment='This is a test upload...', upload_name='Test Upload', text_search_contents=[], publish_time=None, entry_references=None, url='https://nomad-lab.eu/prod/v1/test/api/v1'),\n",
       " NomadEntry(entry_id='7A6lJb-14xR9lxXO8kjuYt5-vxg2', upload_id='DN61X4r7SCyzm5q1kxcEcw', references=[], origin='Joseph Rudzinski', n_quantities=34, nomad_version='1.3.7.dev55+ge83de27b3', upload_create_time=datetime.datetime(2024, 10, 14, 10, 55, 12, 410000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), nomad_commit='', processing_errors=[], entry_name='test.archive.json', last_processing_time=datetime.datetime(2024, 10, 14, 10, 55, 12, 808000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), parser_name='parsers/archive', calc_id='7A6lJb-14xR9lxXO8kjuYt5-vxg2', published=True, writers=[NomadUser(name='Joseph Rudzinski')], processed=True, mainfile='test.archive.json', main_author=NomadUser(name='Joseph Rudzinski'), entry_create_time=datetime.datetime(2024, 10, 14, 10, 55, 12, 563000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), with_embargo=False, entry_type=None, license='CC BY 4.0', domain=None, comment='This is a test upload...', upload_name='Test Upload', text_search_contents=[], publish_time=None, entry_references=None, url='https://nomad-lab.eu/prod/v1/test/api/v1'),\n",
       " NomadEntry(entry_id='jWSpYURP5GgPtgF9LXZJpNlDv-GL', upload_id='z4QvhZ7qSCmgIFv_qJqlyQ', references=[], origin='Joseph Rudzinski', n_quantities=0, nomad_version='1.3.7.dev55+ge83de27b3', upload_create_time=datetime.datetime(2024, 10, 14, 20, 20, 38, 757000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), nomad_commit='', processing_errors=[], entry_name='test.archive.json', last_processing_time=datetime.datetime(2024, 10, 14, 20, 20, 39, 272000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), parser_name='parsers/archive', calc_id='jWSpYURP5GgPtgF9LXZJpNlDv-GL', published=True, writers=[NomadUser(name='Joseph Rudzinski'), NomadUser(name='Joseph Rudzinski')], processed=True, mainfile='test.archive.json', main_author=NomadUser(name='Joseph Rudzinski'), entry_create_time=datetime.datetime(2024, 10, 14, 20, 20, 38, 982000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), with_embargo=False, entry_type=None, license='CC BY 4.0', domain=None, comment='This is a test upload...edited', upload_name='Test Upload', text_search_contents=[], publish_time=datetime.datetime(2024, 10, 15, 6, 18, 27, 700000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), entry_references=None, url='https://nomad-lab.eu/prod/v1/test/api/v1'),\n",
       " NomadEntry(entry_id='MVBIMEZOuIzH7-QFU2TtMIM6LLPp', upload_id='GJdVAOCxRVe-Cwo3qMz9Kg', references=[], origin='Joseph Rudzinski', n_quantities=0, nomad_version='1.3.7.dev55+ge83de27b3', upload_create_time=datetime.datetime(2024, 10, 15, 10, 48, 44, 337000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), nomad_commit='', processing_errors=[], entry_name='test.archive.json', last_processing_time=datetime.datetime(2024, 10, 15, 10, 48, 45, 206000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), parser_name='parsers/archive', calc_id='MVBIMEZOuIzH7-QFU2TtMIM6LLPp', published=True, writers=[NomadUser(name='Joseph Rudzinski')], processed=True, mainfile='test.archive.json', main_author=NomadUser(name='Joseph Rudzinski'), entry_create_time=datetime.datetime(2024, 10, 15, 10, 48, 44, 741000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), with_embargo=False, entry_type=None, license='CC BY 4.0', domain=None, comment='This is a test upload...', upload_name='Test Upload', text_search_contents=[], publish_time=datetime.datetime(2024, 10, 15, 10, 49, 24, 4000, tzinfo=datetime.timezone(datetime.timedelta(0), '+0000')), entry_references=None, url='https://nomad-lab.eu/prod/v1/test/api/v1')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entries_of_my_uploads(url='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Your Own Wrappers\n",
    "\n",
    "In `nomad_utility_workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nomad_utility_workflows",
   "language": "python",
   "name": "nomad_utility_workflows"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
